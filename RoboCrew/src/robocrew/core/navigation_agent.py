import cv2
import base64
import numpy as np
import logging
import time
import os
from typing import List, Optional, Dict, Any
from dotenv import load_dotenv
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage
from langchain.chat_models import init_chat_model

load_dotenv()

from robocrew.core.robot_system import RobotSystem
from robocrew.core.utils import capture_image

logger = logging.getLogger(__name__)

class NavigationAgent:
    def __init__(
        self, 
        robot_system: RobotSystem,
        model_name: str, 
        tools: List[Any],
        system_prompt: str = None,
        history_len: int = 10
    ):
        self.robot = robot_system
        self.tools = tools
        self.tool_map = {t.name: t for t in tools}
        self.history_len = history_len
        
        # Initialize LLM - parse model name for provider
        if "/" in model_name:
            provider, model = model_name.split("/", 1)
            self.llm = init_chat_model(model, model_provider=provider).bind_tools(tools)
        else:
            self.llm = init_chat_model(model_name).bind_tools(tools)
        
        # System Prompt
        base_prompt = """You are an intelligent mobile robot navigating a real physical environment.

CRITICAL: USE YOUR OWN VISUAL JUDGMENT
- YOU must look at the actual image and decide if the path is safe.
- If you see ANY wall or obstacle in front of you, DO NOT MOVE FORWARD.

ROBOT CHARACTERISTICS:
- You are approximately 30cm wide.
- Your camera shows what is directly ahead - walls on the sides WILL hit you if you move forward.
- The wheels drift slightly. After turns, you may not be perfectly aligned.

DOORWAYS AND TIGHT OPENINGS:
- If an opening looks tight (barely wider than you), DO NOT ATTEMPT IT.
- Only go through openings that are clearly at least 2x your width.
- If you must go through a doorway:
  1. Stop and align yourself perfectly centered with the opening
  2. Make micro-adjustments: tiny turns (5-10 degrees) to center yourself
  3. Move forward only 0.1-0.2m at a time
  4. Check your alignment after each tiny move
  5. If you see a wall getting closer on one side, STOP, back up, and re-align
- If unsure whether you'll fit, DON'T TRY. Find another path.

NAVIGATION RULES:
1. LOOK AT THE IMAGE before every move. What do you actually see?
2. If there is a wall in the view, TURN AWAY first.
3. Use TINY movements: 0.1-0.2m forward, 15-30 degree turns.
4. When in doubt, BACK UP and turn.
5. Prefer open spaces. Avoid narrow passages.

WHEN YOU SEE A WALL:
- STOP immediately
- Back up 0.2m
- Turn 45-90 degrees AWAY
- Check again before moving
"""
        self.system_prompt = system_prompt or base_prompt
        self.message_history = [SystemMessage(content=self.system_prompt)]
        
        # State
        self.current_task = "Idle"
        self.last_image = None
        self.stuck_counter = 0

    def set_task(self, task: str):
        """Set a new task for the agent."""
        self.current_task = task
        self.message_history.append(HumanMessage(content=f"New Task: {task}"))
        logger.info(f"Agent task set: {task}")

    def _check_safety(self, image: np.ndarray) -> tuple[list, np.ndarray]:
        """
        Safety check using ObstacleDetector.
        Returns:
            safe_actions (list): List of allowed actions.
            overlay (np.ndarray): Image with visual debugging.
        """
        if image is None:
            return [], image
            
        try:
            # Use import inside method to avoid circular imports layout issues
            import sys
            if os.getcwd() not in sys.path:
                sys.path.append(os.getcwd())
            from obstacle_detection import ObstacleDetector
            
            if not hasattr(self, 'detector'):
                self.detector = ObstacleDetector()
                
            safe_actions, overlay, _ = self.detector.process(image)
            return safe_actions, overlay
                
        except Exception as e:
            logger.error(f"Obstacle detection failed: {e}")
            # Fallback to safe
            return ["FORWARD", "LEFT", "RIGHT", "BACKWARD"], image

    def step(self) -> str:
        """
        Execute one step of the agent loop.
        Returns status string.
        """
        if not self.robot.running:
            return "Robot stopped"
            
        # 1. Capture observation
        frame = self.robot.get_frame()
        if frame is None:
            return "Camera error"
            
        # 2. Safety Check & Processing
        safe_actions, overlay = self._check_safety(frame)
        
        # Use overlay if available, otherwise raw frame
        display_frame = overlay if overlay is not None else frame
        
        # 3. Prepare Prompt
        _, buffer = cv2.imencode('.jpg', display_frame)
        img_base64 = base64.b64encode(buffer).decode('utf-8')
        
        content = [
            {"type": "text", "text": f"Task: {self.current_task}"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{img_base64}"}}
        ]
        
        # Inject Allowed Actions
        content.append({
             "type": "text", 
             "text": f"REFLEX SYSTEM: Allowed actions are {safe_actions}. Green Marked Paths are SAFE. Red Marked Areas are BLOCKED."
        })
            
        self.message_history.append(HumanMessage(content=content))

        
        # 4. LLM Inference
        try:
            response = self.llm.invoke(self.message_history)
            self.message_history.append(response)
            
            # Prune history very aggressively - images take huge tokens
            # Keep only system message + last 2 exchanges (4 messages)
            if len(self.message_history) > 5:
                self.message_history = [self.message_history[0]] + self.message_history[-4:]
            
            # 5. Execute Tools with SAFETY INTERCEPTION
            if response.tool_calls:
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    args = tool_call["args"]
                    logger.info(f"Agent executing: {tool_name}({args})")
                    
                    # --- SAFETY CHECK ---
                    # Map tool names to abstract actions
                    action_map = {
                        "move_forward": "FORWARD",
                        "turn_left": "LEFT",
                        "turn_right": "RIGHT",
                        "move_backward": "BACKWARD"
                    }
                    
                    blocked = False
                    if tool_name in action_map:
                        required_action = action_map[tool_name]
                        if required_action not in safe_actions:
                            blocked = True
                            result = f"REFLEX SYSTEM INTERVENTION: Action '{tool_name}' BLOCKED. detected obstacle. Allowed: {safe_actions}. Please choose another path."
                    
                    if not blocked:
                        if tool_name in self.tool_map:
                            tool = self.tool_map[tool_name]
                            try:
                                result = tool.invoke(args)
                            except Exception as e:
                                result = f"Error executing {tool_name}: {e}"
                        else:
                            result = f"Unknown tool: {tool_name}"
                            logger.error(result)
                            
                    self.message_history.append(ToolMessage(content=str(result), tool_call_id=tool_call["id"]))
                    
                return f"Executed {len(response.tool_calls)} actions"
            else:
                return "Thinking..."
                
        except Exception as e:
            logger.error(f"Agent step error: {e}")
            return f"Error: {e}"
